#!/usr/bin/env python3
"""
üé¨ Film Creative RAG - Demo Launch (Fixed)
==========================================
Launches working Gradio demo with Ollama integration
Fixed Gradio compatibility issue
"""

import gradio as gr
import requests
import json
import sys
import os
from pathlib import Path
import time

class FilmCreativeRAGDemo:
    """Working demo interface for Film Creative RAG"""
    
    def __init__(self):
        self.project_dir = Path.home() / "film-creative-rag"
        self.ollama_url = "http://localhost:11434"
        self.config = self.load_config()
        
        print("üé¨ Film Creative RAG - Demo Launch (Fixed)")
        print("=" * 42)
        print(f"Project directory: {self.project_dir}")
        print("")
    
    def load_config(self):
        """Load Ollama configuration"""
        config_file = self.project_dir / "configs" / "ollama_config.json"
        
        if config_file.exists():
            try:
                with open(config_file, 'r') as f:
                    return json.load(f)
            except:
                pass
        
        # Default configuration
        return {
            "ollama": {
                "url": "http://localhost:11434",
                "default_model": "llama3.2:3b",
                "fallback_model": "llama3.2:1b",
                "timeout": 60,
                "max_tokens": 512,
                "temperature": 0.7
            }
        }
    
    def check_system_status(self):
        """Check if Ollama and models are ready"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json()
                available_models = [model['name'] for model in models.get('models', [])]
                
                # Check for our preferred models
                preferred_models = ["llama3.2:3b", "llama3.2:1b"]
                working_model = None
                
                for model in preferred_models:
                    if model in available_models:
                        working_model = model
                        break
                
                if working_model:
                    return True, working_model, available_models
                else:
                    return False, None, available_models
            else:
                return False, None, []
        except requests.RequestException:
            return False, None, []
    
    def analyze_screenplay(self, screenplay_text, title="Untitled Screenplay"):
        """Analyze screenplay using Ollama"""
        if not screenplay_text.strip():
            return "‚ö†Ô∏è Please enter screenplay content to analyze."
        
        # Check system status
        system_ready, working_model, available_models = self.check_system_status()
        
        if not system_ready:
            if not available_models:
                return """‚ùå **System Not Ready**

**Issue**: Ollama service not responding

**Solutions**:
1. Run: `ollama serve &` in terminal
2. Wait 30 seconds and try again
3. Check if Ollama is installed: `ollama --version`

**Need Help?** Run the setup script: `python3 scripts/setup/02-ollama-setup.py`
"""
            else:
                return f"""‚ùå **Model Not Available**

**Available models**: {', '.join(available_models)}
**Needed**: llama3.2:3b or llama3.2:1b

**Solution**: Run `ollama pull llama3.2:3b` in terminal
"""
        
        try:
            # Create analysis prompt
            prompt = f"""
Analyze this screenplay excerpt and provide a structured analysis:

**Title**: {title}

**Content**:
{screenplay_text}

Please provide:

1. **CHARACTERS**: List all character names mentioned
2. **LOCATION**: Scene setting and location details  
3. **SCENE TYPE**: Interior/Exterior and time of day
4. **MOOD**: Emotional tone and atmosphere
5. **KEY EVENTS**: Important actions or plot points
6. **DIALOGUE NOTES**: Quality and style observations
7. **PRODUCTION NOTES**: Requirements for filming this scene

Analysis:
"""
            
            # Send request to Ollama
            payload = {
                "model": working_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": self.config["ollama"]["temperature"],
                    "max_tokens": self.config["ollama"]["max_tokens"]
                }
            }
            
            print(f"üé≠ Analyzing screenplay '{title}' with {working_model}...")
            
            response = requests.post(
                f"{self.ollama_url}/api/generate", 
                json=payload, 
                timeout=self.config["ollama"]["timeout"]
            )
            
            if response.status_code == 200:
                result = response.json()
                analysis = result.get('response', 'No analysis received')
                
                # Format the response nicely
                formatted_analysis = f"""# üé¨ Screenplay Analysis Complete

## üìù **{title}**

{analysis}

---

‚úÖ **Analysis powered by**: {working_model}  
üîí **Privacy**: All processing done locally on your computer  
‚ö° **Performance**: Optimized for RTX 4090  

*Generated by Film Creative RAG v2.0*
"""
                
                return formatted_analysis
            else:
                return f"""‚ùå **Analysis Failed**

**Error**: Request failed with status {response.status_code}

**Solutions**:
1. Check if Ollama is running: `ollama serve &`
2. Verify model is available: `ollama list`
3. Try again in a few seconds

**Status**: {response.text[:200]}...
"""
                
        except requests.RequestException as e:
            return f"""‚ùå **Connection Error**

**Issue**: Cannot connect to Ollama service

**Error**: {str(e)}

**Solutions**:
1. Start Ollama: `ollama serve &`
2. Wait 30 seconds for startup
3. Try analysis again

**Help**: Run `python3 scripts/setup/02-ollama-setup.py`
"""
        except Exception as e:
            return f"""‚ùå **Unexpected Error**

**Error**: {str(e)}

**Solutions**:
1. Check system status
2. Restart Ollama service
3. Contact support if issue persists
"""
    
    def get_sample_screenplay(self):
        """Return sample screenplay for testing"""
        return """Title: The Digital Breakthrough
Author: Film Creative RAG Demo

FADE IN:

INT. INDIE FILMMAKER'S HOME OFFICE - NIGHT

MAYA, an independent filmmaker in her 30s, sits surrounded by storyboards, script pages, and multiple monitors. Her editing setup shows a documentary project in progress.

MAYA
(exhausted, talking to herself)
This transition between scenes isn't working. The emotional arc feels disconnected.

She pauses the video timeline and rubs her tired eyes. Empty coffee cups and energy drink cans indicate a long night of editing.

MAYA (CONT'D)
(studying her notes)
The interview with Sarah needs to connect better with the archive footage...

Her phone buzzes with a text message from her collaborator.

MAYA (CONT'D)
(reading text, then inspired)
Cross-cutting! That's exactly what this needs.

She starts making rapid edits, cutting between the interview segments and historical footage with renewed energy.

MAYA (CONT'D)
(to her computer)
Let's try alternating between Sarah's memories and the actual events...

The timeline fills with precise cuts as Maya finds the perfect rhythm for her story.

MAYA (CONT'D)
(satisfied)
There it is. The story finally breathes.

She saves her project and leans back, finally satisfied with the edit.

FADE OUT."""
    
    def get_system_info(self):
        """Get current system information"""
        system_ready, working_model, available_models = self.check_system_status()
        
        if system_ready:
            status = f"""üü¢ **SYSTEM STATUS: READY**

‚úÖ **Ollama Service**: Running at {self.ollama_url}
‚úÖ **Active Model**: {working_model}
‚úÖ **Available Models**: {', '.join(available_models)}
‚úÖ **Local Processing**: All analysis done on your computer
‚úÖ **Privacy Mode**: No data sent to external services
‚úÖ **GPU Acceleration**: RTX 4090 optimization ready

üé¨ **Ready for screenplay analysis!**

**Performance**: 
- Analysis time: ~30-60 seconds per screenplay
- Model: {working_model}
- Memory usage: Optimized for creative workflows

**Privacy**: 
- 100% local processing
- Your screenplays never leave your computer
- No cloud connections or data logging
"""
        else:
            status = f"""üî¥ **SYSTEM STATUS: NEEDS ATTENTION**

‚ùå **Ollama Service**: {"Not running" if not available_models else "Running but model missing"}
{"‚ùå" if not available_models else "‚úÖ"} **Available Models**: {', '.join(available_models) if available_models else "None found"}

üîß **Setup Required**:

1. **Start Ollama service**:
   ```bash
   ollama serve &
   ```

2. **Download required model**:
   ```bash
   ollama pull llama3.2:3b
   ```

3. **Refresh this page** and try again

**Need Help?** Run the setup script:
```bash
python3 scripts/setup/02-ollama-setup.py
```

**Status**: Checking {self.ollama_url}
"""
        
        return status
    
    def create_interface(self):
        """Create the Gradio interface with fixed parameters"""
        
        # Custom CSS for professional appearance
        custom_css = """
        .gradio-container {
            font-family: 'Segoe UI', system-ui, -apple-system, sans-serif;
        }
        .main-header {
            text-align: center;
            padding: 2rem;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
            margin-bottom: 2rem;
        }
        """
        
        with gr.Blocks(css=custom_css, title="üé¨ Film Creative RAG") as interface:
            
            # Header
            gr.HTML("""
            <div class="main-header">
                <h1>üé¨ Film Creative RAG</h1>
                <h2>AI-Powered Screenplay Analysis for Independent Filmmakers</h2>
                <p><strong>100% Local Processing ‚Ä¢ Privacy First ‚Ä¢ RTX 4090 Optimized</strong></p>
            </div>
            """)
            
            with gr.Tab("üìù Screenplay Analysis"):
                with gr.Row():
                    with gr.Column(scale=2):
                        title_input = gr.Textbox(
                            label="üìÑ Screenplay Title",
                            placeholder="Enter your screenplay title...",
                            value="My Screenplay"
                        )
                        
                        screenplay_input = gr.Textbox(
                            label="üìú Screenplay Content (Fountain Format Preferred)",
                            placeholder="Paste your screenplay content here...\n\nSupported formats:\n‚Ä¢ Fountain (.fountain)\n‚Ä¢ Plain text\n‚Ä¢ Copy-paste from Final Draft",
                            lines=20
                        )
                        
                        with gr.Row():
                            analyze_btn = gr.Button("üé≠ Analyze Screenplay", variant="primary")
                            sample_btn = gr.Button("üìÑ Load Sample", variant="secondary")
                            clear_btn = gr.Button("üóëÔ∏è Clear", variant="secondary")
                    
                    with gr.Column(scale=2):
                        analysis_output = gr.Textbox(
                            label="ü§ñ AI Analysis Results",
                            lines=25,
                            interactive=False,
                            value="Click 'Analyze Screenplay' to see AI-powered insights about your script..."
                        )
            
            with gr.Tab("‚öôÔ∏è System Status"):
                with gr.Column():
                    gr.HTML("<h3>üîß Film Creative RAG System Status</h3>")
                    
                    status_display = gr.Textbox(
                        label="System Information",
                        lines=20,
                        interactive=False
                    )
                    
                    with gr.Row():
                        refresh_status_btn = gr.Button("üîÑ Refresh Status", variant="secondary")
                        test_connection_btn = gr.Button("üß™ Test Connection", variant="secondary")
            
            with gr.Tab("‚ÑπÔ∏è About & Help"):
                gr.Markdown("""
                ## üé¨ Film Creative RAG System v2.0
                
                ### ‚úÖ System Status: Phase 2 Complete!
                
                **What's Working:**
                - üîß GitHub Integration: Repository with proper workflow
                - ü§ñ Local AI Processing: Ollama + llama3.2:3b model
                - üé≠ Screenplay Analysis: Character, scene, and structure insights
                - üîí Privacy-First: 100% local processing, no cloud connections
                - ‚ö° RTX 4090 Ready: GPU acceleration optimized
                
                ### How to Use This Demo
                1. **Enter screenplay title** in the title field
                2. **Paste screenplay content** (or click "Load Sample")
                3. **Click "Analyze Screenplay"** and wait 30-60 seconds
                4. **Review AI insights** for production planning
                
                ### What You Get
                - **Character Analysis**: Main characters and their roles
                - **Scene Breakdown**: Location, mood, and structure
                - **Production Notes**: Filming requirements and logistics
                - **Creative Insights**: AI suggestions for improvement
                
                ### Privacy & Performance
                - **100% Local**: Your scripts never leave this computer
                - **No Logging**: No data storage or tracking
                - **GPU Optimized**: Fast analysis with RTX 4090
                - **Open Source**: Full transparency in processing
                
                ### Technical Details
                - **LLM**: llama3.2:3b (local model)
                - **Interface**: Gradio web UI
                - **Processing**: Ollama backend
                - **Storage**: Local filesystem only
                
                ### Next Phase: Mood Board Processing
                Phase 3 will add:
                - PDF mood board analysis
                - Visual-narrative alignment
                - Cross-modal intelligence
                - Production planning integration
                
                ---
                
                **üé¨ Film Creative RAG - Made for Independent Filmmakers**
                """)
            
            # Event handlers
            sample_btn.click(
                fn=self.get_sample_screenplay,
                outputs=screenplay_input
            )
            
            clear_btn.click(
                fn=lambda: ("", "Ready for new screenplay analysis..."),
                outputs=[screenplay_input, analysis_output]
            )
            
            analyze_btn.click(
                fn=self.analyze_screenplay,
                inputs=[screenplay_input, title_input],
                outputs=analysis_output
            )
            
            refresh_status_btn.click(
                fn=self.get_system_info,
                outputs=status_display
            )
            
            test_connection_btn.click(
                fn=lambda: self.analyze_screenplay("INT. TEST - DAY\n\nTEST CHARACTER\nThis is a connection test.", "Connection Test"),
                outputs=status_display
            )
            
            # Load initial status when interface starts
            interface.load(
                fn=self.get_system_info,
                outputs=status_display
            )
        
        return interface
    
    def launch_demo(self):
        """Launch the demo interface with fixed Gradio parameters"""
        print("üöÄ Launching Film Creative RAG Demo...")
        print("")
        
        # Check system status before launch
        system_ready, working_model, available_models = self.check_system_status()
        
        if system_ready:
            print("‚úÖ System ready for demo")
            print(f"‚úÖ Using model: {working_model}")
        else:
            print("‚ö†Ô∏è System not fully ready - demo will show setup instructions")
            if available_models:
                print(f"‚ö†Ô∏è Available models: {available_models}")
            else:
                print("‚ö†Ô∏è No models found - Ollama may not be running")
        
        print("")
        print("üåê Demo will be available at: http://localhost:7860")
        print("üé¨ Ready for filmmaker demonstrations!")
        print("")
        print("Press Ctrl+C to stop the demo")
        print("=" * 50)
        
        # Create and launch interface
        interface = self.create_interface()
        
        try:
            # Fixed launch parameters - removed incompatible options
            interface.launch(
                server_name="0.0.0.0",
                server_port=7860,
                share=False,  # Keep it local for privacy
                show_error=True,
                inbrowser=True
            )
        except KeyboardInterrupt:
            print("\nüõë Demo stopped by user")
        except Exception as e:
            print(f"\n‚ùå Demo failed to launch: {e}")
            print("Check Gradio version - may need update")

def main():
    """Main demo launch function"""
    demo = FilmCreativeRAGDemo()
    
    try:
        demo.launch_demo()
    except KeyboardInterrupt:
        print("\n\nüõë Film Creative RAG demo stopped")
    except Exception as e:
        print(f"\n‚ùå Demo error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
